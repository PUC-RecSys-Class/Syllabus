{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ayudantia_4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "Ug0ZdoCQ8v_-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Ayudantía 4 - Sistemas Recomendadores: Content based"
      ]
    },
    {
      "metadata": {
        "id": "8VO7sT3xSI9G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Nombre(s):**"
      ]
    },
    {
      "metadata": {
        "id": "QYb_yqvJ9Azs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ]
    },
    {
      "metadata": {
        "id": "uDf4Fq2sVXoe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Paso 1:** Descarga de archivos que serán utilizados posteriormente.\n",
        "\n",
        "*   Recursos:\n",
        "  * `dictionary.p`\n",
        "  * `dictionary-stemm.p`\n",
        "  * `tfidf_model.p`\n",
        "  * `tfidf_model-stemm.p`\n",
        "*   Dataset:\n",
        "  *  `corpus1.csv`"
      ]
    },
    {
      "metadata": {
        "id": "nAU2KqtbO-H0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Descarga de recursos\n",
        "!curl -L -o 'resources.tar.gz' 'https://github.com/PUC-RecSys-Class/Syllabus/blob/master/Practico%204/files/resources.tar.gz?raw=true'\n",
        "\n",
        "# Descompresión del archivo\n",
        "!tar -xvf resources.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Oe-uwhdrQflY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Descarga del dataset\n",
        "!curl -L -o 'dataset.tar.gz' 'https://github.com/PUC-RecSys-Class/Syllabus/blob/master/Practico%204/files/dataset.tar.gz?raw=true'\n",
        "\n",
        "# Descompresión del archivo\n",
        "!tar -xvf dataset.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C38vKnWX9CFM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Paso 2:** Para este práctico es necesario instalar las siguentes dependencias:"
      ]
    },
    {
      "metadata": {
        "id": "qrQao0AE9ZgV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "!pip install sklearn\n",
        "!pip install gensim\n",
        "!pip install pandas\n",
        "!pip install numpy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gj38t3yY9dMW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "import gensim\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "\n",
        "from collections import Counter\n",
        "from os.path import isfile\n",
        "from textwrap import wrap\n",
        "\n",
        "from gensim import corpora, models, similarities\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import NMF"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PUYnjZ1yOY-A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Preprocesamiento de datos"
      ]
    },
    {
      "metadata": {
        "id": "me-LXrP2Ocjc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Lo primero es descargar las librerías de NLTK necesarias:"
      ]
    },
    {
      "metadata": {
        "id": "1Ru8N7mZ9exU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zUzN9tQTQf2k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Para comenzar cargaremos el set de datos en un *dataframe* de Pandas, e imprimimos los 5 primeros registros para visualizar la estructura de los datos."
      ]
    },
    {
      "metadata": {
        "id": "yk2PJqkW92Ha",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "corpus_df = pd.read_csv('./corpus1.csv', sep='\\t',\n",
        "                        header=None, encoding='latin')\n",
        "corpus_df.columns = ['id', 'title', 'abstract']\n",
        "corpus_df = corpus_df[['id', 'title', 'abstract']]\n",
        "corpus_df.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2c2NWVPnQmFU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Lo siguiente es implementar una función que transforme texto no estructurado a una lista de *tokens* procesados."
      ]
    },
    {
      "metadata": {
        "id": "PerFw5VF-kjf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "stemm = False\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "\n",
        "def get_tokens(text):\n",
        "    lowers = text.lower()\n",
        "    no_punctuation = lowers.translate(\n",
        "        {ord(c): None for c in string.punctuation})\n",
        "    tokens = nltk.word_tokenize(no_punctuation)\n",
        "    if stemm:\n",
        "        tokens = map(stemmer.stem, tokens)\n",
        "\n",
        "    return tokens\n",
        "\n",
        "\n",
        "get_tokens(\"I'm a super student for recommender systems!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5BuNyD3zRUrP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ahora se tiene que generar un diccionario con todas las palabras del *corpus*. Se recomienda revisar la documentación de gensim y leer cómo usar los diccionarios: [corpora.dictionary](https://radimrehurek.com/gensim/corpora/dictionary.html)"
      ]
    },
    {
      "metadata": {
        "id": "HRY9VYwk__HP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dict_file = './resources/dictionary-stemm.p' if stemm else './resources/dictionary.p'\n",
        "if isfile(dict_file):\n",
        "    dictionary = corpora.dictionary.Dictionary().load(dict_file)\n",
        "else:\n",
        "    dictionary = corpora.dictionary.Dictionary(documents=corpus_df.tokenised_abstract.tolist())\n",
        "    dictionary.save(dict_file)\n",
        "    \n",
        "corpus_df['tokenized_abstract'] = corpus_df.abstract.map(get_tokens)\n",
        "corpus_df.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M6QriWJKAMZn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "corpus_df['bow'] = corpus_df.tokenized_abstract.map(dictionary.doc2bow)\n",
        "#del corpus_df['tokenized_abstract']\n",
        "corpus = corpus_df['bow'].tolist()\n",
        "corpus_df.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f23GriULTHgV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Tf-idf"
      ]
    },
    {
      "metadata": {
        "id": "lQqcAAVrfwZw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Esto fue trabjado y comentado durante el último práctico:"
      ]
    },
    {
      "metadata": {
        "id": "C7ju5n3xTKtj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tfidf_model_file = 'resources/tfidf_model-stemm.p' if stemm else 'resources/tfidf_model.p'\n",
        "if isfile(tfidf_model_file):\n",
        "    tfidf_model = models.tfidfmodel.TfidfModel().load(tfidf_model_file)\n",
        "else:\n",
        "    tfidf_model = models.tfidfmodel.TfidfModel(corpus, dictionary=dictionary)\n",
        "    tfidf_model.save(tfidf_model_file)\n",
        "\n",
        "corpus_df['tf_idf'] = tfidf_model[corpus_df.bow.tolist()]\n",
        "corpus_df.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bxqEz_S0ensc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## LDA"
      ]
    },
    {
      "metadata": {
        "id": "hmECljYRgt-g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A continuación utilizaremos el modelo LDA para identificar 10 tópicos sobre los documentos del dataset:"
      ]
    },
    {
      "metadata": {
        "id": "lZI94exTemz4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "topic_number = 10\n",
        "\n",
        "lda_model = models.LdaModel(corpus, num_topics=topic_number,\n",
        "                            id2word=dictionary, passes=5, iterations=200)\n",
        "corpus_df['lda'] = lda_model[corpus_df.bow.tolist()]\n",
        "corpus_df.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2i60zO2fgyVF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Pregunta:** Explique qué representa la columna `lda`, ¿qué significan cada tupla de números?\n",
        "\n",
        "**Respuesta:**"
      ]
    },
    {
      "metadata": {
        "id": "aGcprvI8hbT_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "En la siguiente celda se mostrarán 10 tópicos del modelo LDA."
      ]
    },
    {
      "metadata": {
        "id": "Bjxu2Boug4FB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lda_model.print_topics(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "th7K6SUbhCkf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Pregunta:** ¿Qué representa lo impreso en la celda anterior?\n",
        "\n",
        "**Respuesta:**"
      ]
    },
    {
      "metadata": {
        "id": "g4Cc-fSNhJI6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Pregunta:** A su parecer, ¿son buenos los tópicos encontrados por el modelo? ¿cómo se podrían mejorar?\n",
        "\n",
        "**Respuesta:**"
      ]
    },
    {
      "metadata": {
        "id": "EuNk3cw3SblR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Generar recomendaciones"
      ]
    },
    {
      "metadata": {
        "id": "vHexXEF-SdH2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "En esta sección se implementan las funciones necesarias para poder generar recomendaciones dado lo que un usuario ha consumido. De manera artificial, se \"samplearán\" 3 documentos aleatorios que representarán al usuario objetivo (`sample`). Luego tendrás que generar diferentes recomendaciones y evaluar los resultados."
      ]
    },
    {
      "metadata": {
        "id": "iwM9JHgpAwwu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Random users\n",
        "samples = corpus_df.sample(3)\n",
        "samples_ids = []\n",
        "\n",
        "for n, (ix, paper) in enumerate(samples.iterrows()):\n",
        "    samples_ids.append(ix)\n",
        "    idx, title, abstract, bow, tf_idf, lda = paper[[\n",
        "        'id', 'title', 'abstract', 'bow', 'tf_idf', 'lda']]\n",
        "    print('%d) %s' % (n+1, title))\n",
        "    print('')\n",
        "    print(\"\\n\".join(wrap(abstract)))\n",
        "    print('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IarDHEPrAwm_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Recommendation functions\n",
        "\n",
        "N = len(dictionary)\n",
        "\n",
        "\n",
        "def to_sparse(matrix):\n",
        "    return csr_matrix([\n",
        "        gensim.matutils.sparse2full(row, length=N)\n",
        "        for row in matrix\n",
        "    ])\n",
        "\n",
        "\n",
        "def make_recommendations(model, metric, neighbors):\n",
        "    M = len(corpus)\n",
        "\n",
        "    X = to_sparse(corpus_df[model].tolist())\n",
        "    document_index = NearestNeighbors(\n",
        "        n_neighbors=(neighbors + 1),\n",
        "        algorithm='brute',\n",
        "        metric=metric).fit(X)\n",
        "    return document_index\n",
        "\n",
        "\n",
        "def print_recommendations(indexes, model):\n",
        "    for n, (ix, paper) in enumerate(samples.iterrows()):\n",
        "        dists, neighbors = indexes.kneighbors([gensim.matutils.sparse2full(paper[model], length=N)])\n",
        "        print(paper['title'])\n",
        "        print('')\n",
        "        print('Documentos cercanos: ')\n",
        "        i = 1\n",
        "        for neighbour in neighbors[0]:\n",
        "            if ix != neighbour:\n",
        "                line = str(i) + \". \" + corpus_df.iloc[neighbour]['title']\n",
        "                print(line)\n",
        "                i += 1\n",
        "        print('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dPe8hn3ZTqYO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A continuación deberá utilizar las funciones implementadas anteriormente para generar nuevas recomendaciones variando los parámetros del modelo. **Agregue nuevas celdas para cada implementación y/o pregunta.**\n"
      ]
    },
    {
      "metadata": {
        "id": "wocbAgaljoJy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Aquí hay 2 ejemplos, puede crear más celdas para hacer las pruebas necesarias:"
      ]
    },
    {
      "metadata": {
        "id": "QfHLV4NrA0-U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Recommendation example: TF-IDF\n",
        "doc_idx = make_recommendations('tf_idf', 'euclidean', 5)\n",
        "print_recommendations(doc_idx, 'tf_idf')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IkSP6I1Chm0L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Recommendation example: LDA\n",
        "doc_idx = make_recommendations('lda', 'euclidean', 5)\n",
        "print_recommendations(doc_idx, 'lda')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EXwYjORwTr17",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Pregunta:** Ejecute el modelo utilizando como representación tf-idf y una métrica de distancia euclideana. Modifique el parámetro nearest_neighbors a [5, 10, 20]. ¿Qué efecto tiene este cambio en el modelo en las recomendaciones observadas?\n",
        "\n",
        "**Respuesta:**"
      ]
    },
    {
      "metadata": {
        "id": "CRNEpJy7T6OQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Pregunta:** Eligiendo un valor fijo para *nearest neighbors* y utilizando representación tf-idf, ejecute el modelo con métrica de distancia *cosine*.¿Qué efecto tiene la métrica de distancia en las recomendaciones observadas?\n",
        "\n",
        "**Respuesta:**\n"
      ]
    },
    {
      "metadata": {
        "id": "4AUbaWOpoAvc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Pregunta:** Eligiendo un valor fijo de nearest_neighbors y modelo lda ¿Qué efecto tiene el usar LDA versus TF-IDF en las recomendaciones observadas bajo la misma métrica de distancia?\n",
        "\n",
        "**Respuesta:**"
      ]
    },
    {
      "metadata": {
        "id": "GfgYZ8SLoFsV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Pregunta:** Pruebe nuevamente con LDA usando 5 tópicos y con 20 tópicos ¿qué efecto tiene el número de tópicos en las recomendaciones observadas?\n",
        "\n",
        "**Respuesta:**"
      ]
    },
    {
      "metadata": {
        "id": "gfInn_xVSmZ6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Stop words"
      ]
    },
    {
      "metadata": {
        "id": "1LgcEzIcxM4W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A continuación, intentaremos mejorar los resultados obtenidos con LDA eliminando las *stopwords*. ¿Qué son las *stopwords*? Son palabras vacías, sin significado, que no aportan (de manera significativa) al sentido de una frase, como los artículos, pronombres, etc."
      ]
    },
    {
      "metadata": {
        "id": "aNlhgqHaVZuE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mTKiDBwpoJ4A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    filtered_words = [\n",
        "        word for word in text if word not in stopwords.words('english')\n",
        "    ]\n",
        "    return filtered_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cQFhKTk1xM4p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ahora, repetimos el proceso realizado anteriormente (sin tanto detalle, ya que estos se comentaron previamente)"
      ]
    },
    {
      "metadata": {
        "id": "DqQRTEtiUf1n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Puede que se demore un poco esta celda\n",
        "corpus_df['tokenized_abstract_without_stopwords'] = corpus_df.tokenized_abstract.map(remove_stopwords)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zsAcYiECX0FO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "corpus_df['bow_without_stopwords'] = corpus_df.tokenized_abstract_without_stopwords.map(dictionary.doc2bow)\n",
        "del corpus_df['tokenized_abstract_without_stopwords']\n",
        "corpus = corpus_df['bow_without_stopwords'].tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J2CWQqabaUFo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tfidf_model_file_without_stopwords = 'resources/tfidf_model-stemm.p' if stemm else 'resources/tfidf_model.p'\n",
        "if isfile(tfidf_model_file):\n",
        "    tfidf_model_without_stopwords = models.tfidfmodel.TfidfModel().load(tfidf_model_file)\n",
        "else:\n",
        "    tfidf_model_without_stopwords = models.tfidfmodel.TfidfModel(corpus, dictionary=dictionary)\n",
        "    tfidf_model_without_stopwords.save(tfidf_model_file_without_stopwords)\n",
        "\n",
        "corpus_df['tf_idf_without_stopwords'] = tfidf_model_without_stopwords[corpus_df.bow_without_stopwords.tolist()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ncp8832Uataa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "topic_number = 10\n",
        "\n",
        "lda_model_without_stopwords = models.LdaModel(corpus, num_topics=topic_number, id2word=dictionary, passes=5, iterations=200)\n",
        "corpus_df['lda_without_stopwords'] = lda_model_without_stopwords[corpus_df.bow_without_stopwords.tolist()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ah0mFrEWhXgA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lda_model_without_stopwords.print_topics(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yaclTipvxM5E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Pregunta:** ¿Qué puede decir de estos nuevos tópicos comparándolos con los obtenidos previamente (sección LDA)?\n",
        "\n",
        "**Respuesta:**"
      ]
    },
    {
      "metadata": {
        "id": "_ODPKrtce-6O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Rellocate user\n",
        "\n",
        "samples = corpus_df.iloc[samples_ids]\n",
        "\n",
        "for n, (ix, paper) in enumerate(samples.iterrows()):\n",
        "    idx, title, abstract, bow, tf_idf, lda, bow_without_stopwords, tf_idf_without_stopwords, lda_without_stopwords = paper[[\n",
        "        'id', 'title', 'abstract', 'bow', 'tf_idf', 'lda', 'bow_without_stopwords', 'tf_idf_without_stopwords', 'lda_without_stopwords']]\n",
        "    print('%d) %s' % (n+1, title))\n",
        "    print('')\n",
        "    print(\"\\n\".join(wrap(abstract)))\n",
        "    print('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ioMco6YHf2ex",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Pregunta:** Compare las recomendaciones hechas por los métodos cuando quitamos las *stopwords* del diccionario con su versión de las secciones anteriores.\n",
        "\n",
        "**Respuesta:**"
      ]
    },
    {
      "metadata": {
        "id": "uIfyEAdGxgoK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Pregunta:** ¿Cómo cambian las recomendaciones entre ambos métodos ahora que no consideramos las *stopwords*?\n",
        "\n",
        "**Respuesta:**"
      ]
    },
    {
      "metadata": {
        "id": "scQsJAc7cOhV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Recommendation example: TF-IDF without stopwords\n",
        "\n",
        "doc_idx = make_recommendations('tf_idf_without_stopwords', 'euclidean', 5)\n",
        "print_recommendations(doc_idx, 'tf_idf_without_stopwords')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RUXP52_Kckb_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Recommendation example: LDA without stopwords\n",
        "\n",
        "doc_idx = make_recommendations('lda_without_stopwords', 'euclidean', 5)\n",
        "print_recommendations(doc_idx, 'lda_without_stopwords')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ncn1B8W5mPWb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Pregunta:** Realice el siguiente gráfico. Pruebe graficando los items con respecto al tópico con mayor probabilidad de pertenencia, para poder hacer el gráfico deberá usar algún método de reducción de dimensionalidad como PCA o T-SNE a los valores de LDA que están en el dataframe.\n",
        "\n",
        "Ejemplo:"
      ]
    },
    {
      "metadata": {
        "id": "rauMml6Hquox",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![Expected plot](https://raw.githubusercontent.com/PUC-RecSys-Class/Syllabus/master/Practico%204/files/plot.png)"
      ]
    },
    {
      "metadata": {
        "id": "LALKKBQcnzlg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Codigo para generar el grafico"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X60ZefJhxM5c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Otro método: Non-negative Matrix Factorization (NMF)"
      ]
    },
    {
      "metadata": {
        "id": "Rs2eNlQWnAK2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A continuación, utilizaremos el modelo NMF para generar recomendaciones:"
      ]
    },
    {
      "metadata": {
        "id": "qXlGYDIcjcKi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_components = 10\n",
        "n_top_words = 20\n",
        "\n",
        "\n",
        "def print_top_words(model, feature_names, n_top_words):\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        message = \"Tópico #%d: \" % topic_idx\n",
        "        message += \" \".join([feature_names[i]\n",
        "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
        "        print(message)\n",
        "        print()\n",
        "    print()\n",
        "\n",
        "\n",
        "data_samples = corpus_df['abstract'].values\n",
        "\n",
        "# Formato TF-IDF de sklearn\n",
        "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
        "tfidf = tfidf_vectorizer.fit_transform(data_samples)\n",
        "\n",
        "# Fit NMF\n",
        "nmf = NMF(n_components=n_components, random_state=1,\n",
        "          alpha=.1, l1_ratio=.5,\n",
        "          ).fit(tfidf)\n",
        "nmf_transform_1 = nmf.transform(tfidf)\n",
        "# Display NMF\n",
        "print(\"Tópicos:\")\n",
        "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
        "print_top_words(nmf, tfidf_feature_names, n_top_words)\n",
        "print()\n",
        "print()\n",
        "\n",
        "# Fit NMF with KL-Divergence\n",
        "nmf = NMF(n_components=n_components, random_state=1,\n",
        "          beta_loss='kullback-leibler', solver='mu', max_iter=1000, alpha=.1,\n",
        "          l1_ratio=.5,\n",
        "          ).fit(tfidf)\n",
        "# Display NMF with KL-Divergence\n",
        "print(\"Tópicos con divergencia KL:\")\n",
        "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
        "print_top_words(nmf, tfidf_feature_names, n_top_words)\n",
        "print()\n",
        "print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iGQPLsSOo17R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Pregunta:** ¿Le parece significativa la diferencia en la calidad de los tópicos al usar la divergencia KL? ¿Son mejores estos tópicos que los obtenidos anteriormente?\n",
        "\n",
        "**Respuesta:**"
      ]
    },
    {
      "metadata": {
        "id": "Mwv337wWoX6e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Agregamos los valores obtenidos como una columna en el *dataframe*:"
      ]
    },
    {
      "metadata": {
        "id": "96s0zV2PqttB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "corpus_df['NMF'] = [[(i, prob) for i, prob in enumerate(l)] for l in nmf_transform_1.tolist()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mz2ybg7KowBA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Pregunta:** Explique qué representa la columna `NMF`, ¿qué significan los valores?\n",
        "\n",
        "**Respuesta:**"
      ]
    },
    {
      "metadata": {
        "id": "jXLq5NDiodTp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Repetimos el proceso de *sampling* para inspeccionar los resultados:"
      ]
    },
    {
      "metadata": {
        "id": "h3kaYZhntt5X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Rellocate user\n",
        "\n",
        "samples = corpus_df.iloc[samples_ids]\n",
        "\n",
        "for n, (ix, paper) in enumerate(samples.iterrows()):\n",
        "    idx, title, abstract, bow, tf_idf, lda, bow_without_stopwords, tf_idf_without_stopwords, lda_without_stopwords, nmf = paper[[\n",
        "        'id', 'title', 'abstract', 'bow', 'tf_idf', 'lda', 'bow_without_stopwords', 'tf_idf_without_stopwords', 'lda_without_stopwords', 'NMF']]\n",
        "    print('%d) %s' % (n+1, title))\n",
        "    print('')\n",
        "    print(\"\\n\".join(wrap(abstract)))\n",
        "    print('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nl155tv3pMnW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Pregunta:** Compare y comente sobre las recomendaciones hechas por los métodos anteriores con las obtenidas usando NMF.\n",
        "\n",
        "**Respuesta:**"
      ]
    },
    {
      "metadata": {
        "id": "ZIwj5hu3sVRn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "doc_idx = make_recommendations('NMF', 'euclidean', 5)\n",
        "print_recommendations(doc_idx, 'NMF')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}