{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Práctico pyreclab 3",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "Ug0ZdoCQ8v_-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Ayudantía 3 - Sistemas Recomendadores: Pyreclab"
      ]
    },
    {
      "metadata": {
        "id": "8VO7sT3xSI9G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Nombre(s):**"
      ]
    },
    {
      "metadata": {
        "id": "QYb_yqvJ9Azs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ]
    },
    {
      "metadata": {
        "id": "uDf4Fq2sVXoe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Paso 1:** Descarga de archivos:\n",
        "\n",
        "*   `dictionary.p`\n",
        "*   `dictionary-stemm.p`\n",
        "*  `tfidf_model.p`\n",
        "*  `tfidf_model-stemm.p`"
      ]
    },
    {
      "metadata": {
        "id": "nAU2KqtbO-H0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Descargue los archivos ejecutando este comando\n",
        "!curl -L -o 'resources.tar.gz' \"https://drive.google.com/uc?export=download&id=1_Vp-veFfqCFkaEs-qVx99DYrAexBfq8w\"\n",
        "\n",
        "# Descomprima el archivo\n",
        "!tar -xvf resources.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LdcX_Hv8VtMC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Paso 1.5:** Descarga del dataset:"
      ]
    },
    {
      "metadata": {
        "id": "Oe-uwhdrQflY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Puede descargar el dataset ejecutando el siguiente comando\n",
        "!curl -L -o 'dataset.tar.gz' \"https://drive.google.com/uc?export=download&id=1by4BZRPeUSnQRbwJWc-OKpIF6YBpCa7s\"\n",
        "\n",
        "# Y descomprimirlo con\n",
        "!tar -xvf dataset.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C38vKnWX9CFM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Paso 2:** Para este práctico es necesario instalar las siguentes dependencias:"
      ]
    },
    {
      "metadata": {
        "id": "qrQao0AE9ZgV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "!pip install sklearn\n",
        "!pip install gensim\n",
        "!pip install pandas\n",
        "!pip install numpy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gj38t3yY9dMW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import nltk\n",
        "import sklearn\n",
        "import gensim\n",
        "import string\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer \n",
        "from gensim import corpora, models, similarities\n",
        "from sklearn.neighbors import NearestNeighbors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PUYnjZ1yOY-A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Preprocesamiento de datos"
      ]
    },
    {
      "metadata": {
        "id": "me-LXrP2Ocjc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Lo primero es descargar las librerías de NLTK necesarias:"
      ]
    },
    {
      "metadata": {
        "id": "1Ru8N7mZ9exU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Download corpora\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zUzN9tQTQf2k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Para comenzar cargaremos el set de datos en un *dataframe* de Pandas, e imprimimos los 5 primeros registros para visualizar la estructura de los datos."
      ]
    },
    {
      "metadata": {
        "id": "yk2PJqkW92Ha",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "corpus_df = pd.read_csv('./corpus1.csv', sep='\\t', header=None, encoding='latin')\n",
        "corpus_df.columns = ['id', 'title', 'abstract']\n",
        "corpus_df = corpus_df[['id', 'title', 'abstract']]\n",
        "corpus_df[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2c2NWVPnQmFU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Lo siguiente es implementar una función que transforme texto no estructurado a una lista de tokens procesados."
      ]
    },
    {
      "metadata": {
        "id": "PerFw5VF-kjf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "stemm = False\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def get_tokens(text):\n",
        "    lowers = text.lower()\n",
        "    no_punctuation = lowers.translate(string.punctuation)\n",
        "    tokens = nltk.word_tokenize(no_punctuation)\n",
        "    if stemm:\n",
        "        tokens = map(stemmer.stem, tokens)\n",
        "    return tokens\n",
        "\n",
        "get_tokens(\"I'm a super student for recommender systems!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3csGVr5GQwnR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Pregunta:** Explique en sus palabras qué hace la función `get_tokens()`.\n",
        "\n",
        "**Respuesta:**\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "5BuNyD3zRUrP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ahora se tiene que generar un diccionario con todas las palabras del *corpus*.\n",
        "\n",
        "Se recomienda revisar la documentación de gensim y leer cómo usar los diccionarios: [corpora.dictionary](https://radimrehurek.com/gensim/corpora/dictionary.html)"
      ]
    },
    {
      "metadata": {
        "id": "HRY9VYwk__HP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dict_file = './resources/dictionary-stemm.p' if stemm else './resources/dictionary.p'\n",
        "if os.path.isfile(dict_file):\n",
        "    dictionary = corpora.dictionary.Dictionary().load(dict_file)\n",
        "else:\n",
        "    dictionary = corpora.dictionary.Dictionary(documents=corpus_df.tokenised_abstract.tolist())\n",
        "    dictionary.save(dict_file)\n",
        "    \n",
        "corpus_df['tokenized_abstract'] = corpus_df.abstract.map(get_tokens)\n",
        "corpus_df[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BB7mwxklRxs_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Pregunta:** Explique a qué corresponde la columna `tokenised_abstract` del dataframe.\n",
        "\n",
        "**Respuesta:**\n",
        "\n",
        "`\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "M6QriWJKAMZn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "corpus_df['bow'] = corpus_df.tokenized_abstract.map(dictionary.doc2bow)\n",
        "del corpus_df['tokenized_abstract']\n",
        "corpus = corpus_df['bow'].tolist()\n",
        "corpus_df[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BtaBE7snSDMe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Pregunta:** Explique a qué corresponde la columna `bow`\n",
        "\n",
        "**Respuesta:**\n"
      ]
    },
    {
      "metadata": {
        "id": "f23GriULTHgV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Tf-idf"
      ]
    },
    {
      "metadata": {
        "id": "C7ju5n3xTKtj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tfidf_model_file = 'resources/tfidf_model-stemm.p' if stemm else 'resources/tfidf_model.p'\n",
        "if os.path.isfile(tfidf_model_file):\n",
        "    tfidf_model = models.tfidfmodel.TfidfModel().load(tfidf_model_file)\n",
        "else:\n",
        "    tfidf_model = models.tfidfmodel.TfidfModel(corpus, dictionary=dictionary)\n",
        "    tfidf_model.save(tfidf_model_file)\n",
        "\n",
        "corpus_df['tf_idf'] = tfidf_model[corpus_df.bow.tolist()]\n",
        "corpus_df[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O8F8BfFvTUz8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Pregunta:** Explicar a qué corresponde la columna `tf_idf` y por qué es útil en el procesamiento de texto. Mencione sus 2 principales partes, mediante la explicación del puntaje.\n",
        "\n",
        "**Respuesta:**"
      ]
    },
    {
      "metadata": {
        "id": "EuNk3cw3SblR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Generar recomendaciones"
      ]
    },
    {
      "metadata": {
        "id": "vHexXEF-SdH2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "En esta sección se implementan las funciones necesarias para poder generar recomendaciones dado lo que un usuario ha consumido. De manera artificial, se samplearán 3 documentos aleatorios que representarán al usuario objetivo (`sample`). Luego tendrás que generar diferentes recomendaciones y evaluar los resultados."
      ]
    },
    {
      "metadata": {
        "id": "iwM9JHgpAwwu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Random user\n",
        "\n",
        "samples = corpus_df.sample(3)\n",
        "\n",
        "for n, (ix, paper) in enumerate(samples.iterrows()):\n",
        "  idx, title, abstract, bow, tf_idf = paper\n",
        "  print('%d) %s' % (n+1, title))\n",
        "  print('')\n",
        "  print(abstract)\n",
        "  print('\\n' )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IarDHEPrAwm_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Recommendation functions\n",
        "\n",
        "N = len(dictionary)\n",
        "\n",
        "def to_sparse(matrix):\n",
        "    return csr_matrix([gensim.matutils.sparse2full(row, length=N) for row in matrix]) \n",
        "\n",
        "def make_recommendations(model, metric, neighbors):\n",
        "    M = len(corpus)\n",
        "\n",
        "    X = to_sparse(corpus_df[model].tolist())\n",
        "    document_index = NearestNeighbors(n_neighbors=(neighbors + 1), algorithm='brute', metric=metric).fit(X)\n",
        "    return document_index\n",
        "\n",
        "def print_recommendations(indexes, model):\n",
        "    for n, (ix, paper) in enumerate(samples.iterrows()):\n",
        "        dists, neighbors = indexes.kneighbors([gensim.matutils.sparse2full(paper[model],length=N)])\n",
        "        print(paper['title'])\n",
        "        print('')\n",
        "        print('Documentos cercanos: ')\n",
        "        i = 1\n",
        "        for neighbour in neighbors[0]:\n",
        "            if ix != neighbour:\n",
        "                line = str(i) + \". \" + corpus_df.iloc[neighbour]['title']\n",
        "                print(line)\n",
        "                i+=1\n",
        "        print('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dPe8hn3ZTqYO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A continuación deberá utilizar las funciones implementadas anteriormente para generar nuevas recomendaciones variando los parámetros del modelo. Agregue nuevas celdas para cada implementación y/o pregunta.\n"
      ]
    },
    {
      "metadata": {
        "id": "EXwYjORwTr17",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "** Pregunta:** Ejecute el modelo utilizando como representación tf-idf y una métrica de distancia euclideana. Modifique el parámetro nearest_neighbors a [5, 10, 20]. ¿qué efecto tiene el modelo en las recomendaciones observadas?\n",
        "\n",
        "**Respuesta:**"
      ]
    },
    {
      "metadata": {
        "id": "CRNEpJy7T6OQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Pregunta:** Eligiendo un valor fijo para *nearest neighbors* y utilizando representación tf-idf, ejecute el modelo con métrica de distancia *cosine*.¿Qué efecto tiene la métrica de distancia en las recomendaciones observadas?\n",
        "\n",
        "**Respuesta:**\n"
      ]
    },
    {
      "metadata": {
        "id": "QfHLV4NrA0-U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Recommendation example\n",
        " \n",
        "doc_idx = make_recommendations('tf_idf', 'euclidean', 5)\n",
        "print_recommendations(doc_idx, 'tf_idf')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wFFs8vtUSQC0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}